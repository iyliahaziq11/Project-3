{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e038058",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1127fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "\n",
    "from psaw import PushshiftAPI\n",
    "import praw\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ce374",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b4e952",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f33ad",
   "metadata": {},
   "source": [
    "### Import data for 2 types of modeling :\n",
    "1. Using logistic regression / KNN\n",
    "2. Using NLP Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a1f9d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_csv(\"/Users/mohammadiyliahaziq/Desktop/GA/dsi25-workspace/project_3/data/df_for_modelling_top2500.csv\")\n",
    "df_combined = df_combined.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fcd782",
   "metadata": {},
   "source": [
    "**We take the top 2500 posts in each category and proceed with logistic regression**\n",
    "- first we convert `created_utc` column into `day` and `hour` columns\n",
    "- then we onehotencode the target variable `subreddit` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cc3b3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting and splitting the created_utc column into its\n",
    "# respective month, day, hour columns\n",
    "df_combined['created_utc'] = df_combined['created_utc'].map(lambda x:\n",
    "                                                    datetime.datetime.fromtimestamp(x))\n",
    "\n",
    "df_combined['day'] =  df_combined['created_utc'].dt.day\n",
    "df_combined['hour'] =  df_combined['created_utc'].dt.hour\n",
    "\n",
    "# dropping columns that are not required\n",
    "df_combined = df_combined.drop(columns=['created_utc','title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8855b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the target variable subreddit column into 1 and 0, where\n",
    "# 1 indicates that the post is from r/news and \n",
    "# 0 indicates that the post is from r/TheOnion\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "df_combined['subreddit'].replace({'news':1,'TheOnion': 0}, inplace=True)\n",
    "\n",
    "# shifting the target variable subreddit column to the last column \n",
    "temp = df_combined['subreddit']\n",
    "df_combined = pd.concat((df_combined.drop(columns='subreddit'),temp),axis=1)\n",
    "\n",
    "\n",
    "df_combined = df_combined.astype({'day':'object', 'hour':'object'})\n",
    "df_combined = pd.get_dummies(df_combined, columns=['day','hour'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de38537b",
   "metadata": {},
   "source": [
    "**Dummify categorical variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d669fa",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83ae67",
   "metadata": {},
   "source": [
    "# Modeling - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "033453ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the rows\n",
    "# df_combined = df_combined.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aafb94",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">QUESTION</span>\n",
    "- fit_transform\n",
    "- standard scaler ==> results drop\n",
    "- does it help to show our model's performance on more unseen data?\n",
    "- how to make sense of the Naive Bayes scores ==> how do we intepret the highest scoring features?\n",
    "- should i use DT/RF/boosting if they all show 0.99?\n",
    "- jupyter notebook organisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ce7b1007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 58)\n",
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "# Why when dont apply standarscaler, results improve but result for external set is very poor?\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_combined.drop(columns='subreddit'),\n",
    "                                                   df_combined['subreddit'], test_size=0.2,\n",
    "                                                   random_state=24)\n",
    "# apply standardscaler\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)\n",
    "\n",
    "# dont apply standardscaler\n",
    "# X_train_sc = X_train\n",
    "# X_test_sc = X_test\n",
    "\n",
    "print(X_train_sc.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6288d5",
   "metadata": {},
   "source": [
    "**deploy and evaluate model**\n",
    "- QUESTION: WHY DOES STANDARD SCALER GIVE WORSE RESULT?\n",
    "- w/o ss: train/test 0.96/0.95\n",
    "- w ss: train/test 0.86/0.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "11c7ce5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96825\n",
      "0.956\n"
     ]
    }
   ],
   "source": [
    "LogReg = LogisticRegression(solver='liblinear')\n",
    "LogReg.fit(X_train_sc, y_train)\n",
    "y_pred = LogReg.predict(X_test_sc)\n",
    "print(LogReg.score(X_train_sc, y_train))\n",
    "print(LogReg.score(X_test_sc, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938886a7",
   "metadata": {},
   "source": [
    "#### GridSearchCV for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "57f1f979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'l1_ratio': 0.25, 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# use GridSearchCV to find the hyperparameters that gives the best modelling scores \n",
    "LogReg = LogisticRegression()\n",
    "LogReg = GridSearchCV(estimator=LogReg, param_grid={'C': [1,10,20], 'solver':['newton-cg','liblinear','lbfgs'],\n",
    "                      'l1_ratio':[0.25,0.5,0.75]}, verbose = 1, cv =5, return_train_score = False)\n",
    "\n",
    "# fit scaled train data into the Logistic Regression GridSearch model \n",
    "LogReg.fit(X_train_sc, y_train)\n",
    "LogReg.cv_results_\n",
    "# df = pd.DataFrame(LogReg.cv_results_)\n",
    "# df = df[['mean_test_score','param_solver','param_l1_ratio','param_C']]\n",
    "# df.sort_values(by='mean_test_score', ascending=False).head()\n",
    "LogReg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "543933ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9675\n",
      "0.955\n"
     ]
    }
   ],
   "source": [
    "# apply the best hyperparameters which we got from GridSearch above into our model.\n",
    "LogReg_GridSearch = LogisticRegression(C= 20, l1_ratio= 0.25, solver= 'newton-cg')\n",
    "LogReg_GridSearch.fit(X_train_sc, y_train)\n",
    "y_pred = LogReg_GridSearch.predict(X_test_sc)\n",
    "print(LogReg_GridSearch.score(X_train_sc, y_train))\n",
    "print(LogReg_GridSearch.score(X_test_sc, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0d0e7",
   "metadata": {},
   "source": [
    "# Visualizing additional external datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "33d9ae7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1968"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_testext = pd.read_csv('df_news.csv')\n",
    "df_onion_testext = pd.read_csv('df_onion.csv')\n",
    "df_news_testext['subreddit'] = 1\n",
    "df_onion_testext['subreddit'] = 0\n",
    "df_news_testext['num_char'] = df_news_testext['title'].map(lambda x: len(x))\n",
    "df_onion_testext['num_char'] = df_onion_testext['title'].map(lambda x: len(x))\n",
    "df_combined_testext = pd.concat((df_news_testext,df_onion_testext), axis=0)\n",
    "df_combined_testext = df_combined_testext.sample(frac=1).reset_index(drop=True)\n",
    "len(set(df_combined_testext.title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6b7f4259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_testext = df_combined_testext.drop(columns='Unnamed: 0')\n",
    "\n",
    "# converting\n",
    "# and splitting the created_utc column into its\n",
    "# respective month, day, hour columns\n",
    "df_combined_testext['created_utc'] = df_combined_testext['created_utc'].map(lambda x:\n",
    "                                                    datetime.datetime.fromtimestamp(x))\n",
    "\n",
    "df_combined_testext['day'] =  df_combined_testext['created_utc'].dt.day\n",
    "df_combined_testext['hour'] =  df_combined_testext['created_utc'].dt.hour\n",
    "\n",
    "# dropping columns that are not required\n",
    "df_combined_testext = df_combined_testext.drop(columns=['created_utc', 'selftext'])\n",
    "df_combined_testext = df_combined_testext.astype({'day':'object', 'hour':'object'})\n",
    "df_combined_testext = pd.get_dummies(df_combined_testext, columns=['day','hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "982bd2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5230460921843687\n"
     ]
    }
   ],
   "source": [
    "X = df_combined_testext.drop(columns=['title','subreddit'])\n",
    "y = df_combined_testext['subreddit']\n",
    "\n",
    "# X_sc = X\n",
    "ss = StandardScaler()\n",
    "X_sc = ss.fit_transform(X)\n",
    "y_pred = LogReg_GridSearch.predict(X_sc)\n",
    "print(LogReg_GridSearch.score(X_sc,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d7954",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
